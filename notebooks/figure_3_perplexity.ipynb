{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "# Enable hot autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, LlamaForCausalLM\n",
    "from utils import compute_perplexity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_TOKENIZER_PATH = \"<LLAMA_TOKENIZER_PATH>\"\n",
    "LLAMA_MODEL_PATH = \"<LLAMA_MODEL_PATH>\"\n",
    "\n",
    "# pickled pd.DataFrame, produced by inject_traps.py\n",
    "TRAP_INFO_PATH = \"<TRAP_INFO_PATH>\"\n",
    "\n",
    "# We've generated additional non-member canaries with the scripts `gen_traps.py`\n",
    "NON_MEMBERS_PATH_TEMPLATE = \"<PATH_TO_NON_MEMBER_TRAPS_SEQ_LEN_%d>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_tokenizer = LlamaTokenizer.from_pretrained(LLAMA_TOKENIZER_PATH, torch_dtype=torch.float16)\n",
    "llama_model = LlamaForCausalLM.from_pretrained(LLAMA_MODEL_PATH)\n",
    "\n",
    "croissant_tokenizer = AutoTokenizer.from_pretrained(\"croissantllm/base_190k\")\n",
    "croissant_model = AutoModelForCausalLM.from_pretrained(\"croissantllm/base_190k\")\n",
    "\n",
    "croissant_tokenizer.pad_token = croissant_tokenizer.eos_token\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "\n",
    "croissant_model = croissant_model.to(\"cuda:0\")\n",
    "llama_model = llama_model.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAP_INFO_PATH, \"rb\") as f:\n",
    "    trap_info = pickle.load(f)\n",
    "trap_info[\"raw_canaries\"] = llama_tokenizer.batch_decode(trap_info.canary_tokens)\n",
    "\n",
    "non_members = {}\n",
    "for seq_len in [25, 50, 100]:\n",
    "    nm_path = NON_MEMBERS_PATH_TEMPLATE % seq_len\n",
    "    with open(nm_path, \"rb\") as f:\n",
    "        non_members[seq_len] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rep = 1000\n",
    "seq_len = 100\n",
    "ppl_set = set(trap_info.ppl_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame()\n",
    "\n",
    "for ppl in ppl_set:\n",
    "    df_filter = trap_info[\n",
    "        (trap_info.seq_len == seq_len)\n",
    "        & (trap_info.ppl_bucket == ppl)\n",
    "        & (trap_info.n_rep == n_rep)\n",
    "    ]\n",
    "\n",
    "    df_res_tmp = compute_perplexity_df(\n",
    "        llama_model=llama_model,\n",
    "        croissant_model=croissant_model,\n",
    "        llama_tokenizer=llama_tokenizer,\n",
    "        croissant_tokenizer=croissant_tokenizer,\n",
    "        raw_canaries=df_filter.raw_canaries,\n",
    "    )\n",
    "\n",
    "    df_res_tmp[\"seq_len\"] = seq_len\n",
    "    df_res_tmp[\"ppl\"] = ppl\n",
    "    df_res_tmp[\"n_rep\"] = n_rep\n",
    "\n",
    "    df_res = pd.concat([df_res, df_res_tmp])\n",
    "\n",
    "\n",
    "for ppl in ppl_set:\n",
    "    key = (ppl * 10 + 1, ppl * 10 + 11)\n",
    "    raw_canaries = llama_tokenizer.batch_decode(non_members[seq_len][key][:, 1:])\n",
    "\n",
    "    df_res_tmp = compute_perplexity_df(\n",
    "        llama_model=llama_model,\n",
    "        croissant_model=croissant_model,\n",
    "        llama_tokenizer=llama_tokenizer,\n",
    "        croissant_tokenizer=croissant_tokenizer,\n",
    "        raw_canaries=raw_canaries,\n",
    "    )\n",
    "    df_res_tmp[\"seq_len\"] = seq_len\n",
    "    df_res_tmp[\"ppl\"] = ppl\n",
    "    df_res_tmp[\"n_rep\"] = 0\n",
    "\n",
    "    df_res = pd.concat([df_res, df_res_tmp])\n",
    "    \n",
    "df_res[\"ratio\"] = df_res.croissant_ppl / df_res.llama_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for ppl in range(10):\n",
    "    y_true = []\n",
    "    y_ratio = []\n",
    "\n",
    "    members_tmp = df_res[(df_res.seq_len == seq_len) & (df_res.n_rep == n_rep) & (df_res.ppl == ppl)]\n",
    "    non_members_tmp = df_res[(df_res.seq_len == seq_len) & (df_res.n_rep == 0) & (df_res.ppl == ppl)]\n",
    "\n",
    "    y_ratio.extend(members_tmp[\"ratio\"])\n",
    "    y_ratio.extend(non_members_tmp[\"ratio\"])\n",
    "    y_true.extend([0] * len(members_tmp))\n",
    "    y_true.extend([1] * len(non_members_tmp))\n",
    "    fpr_ratio, tpr_ratio, _ = roc_curve(y_true, y_ratio)\n",
    "    auc_ratio = auc(fpr_ratio, tpr_ratio)\n",
    "\n",
    "    data.append((ppl, auc_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(5, 5), sharey=True)\n",
    "\n",
    "x, y = zip(*data)\n",
    "x = np.array(x) * 10\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "pearson_coeff, pearson_p_value = pearsonr(x, y)\n",
    "\n",
    "axes.scatter(\n",
    "    x + 5,\n",
    "    y,\n",
    "    label=r\"$L_\\text{ref} = %d, n_\\text{rep} = %d$\" % (seq_len, n_rep),\n",
    "    s=60,\n",
    "    c=\"darkgreen\",\n",
    "    linewidths=0.5,\n",
    "    marker=\"o\",\n",
    ")\n",
    "axes.plot(x + 5, slope * np.array(x) + intercept, color=\"dimgrey\", linestyle=\"--\", label=\"Linear fit\")\n",
    "axes.grid()  # Move this line below plt.scatter()\n",
    "axes.set_axisbelow(True)\n",
    "\n",
    "\n",
    "axes.axhline(0.5, linestyle=\"--\", linewidth=2, c=\"black\", alpha=1, label=\"Random guess baseline\")\n",
    "plt.xlabel(\"Trap sequence perplexity\", fontsize=15)\n",
    "plt.ylabel(\"AUC\", fontsize=17)\n",
    "\n",
    "\n",
    "axes.set_ylim(0.3, 0.9)\n",
    "axes.set_xlim(0, 100)\n",
    "axes.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"seq_len={seq_len}, n_rep={n_rep}, pearson = {pearson_coeff:.3f}, p_value = {pearson_p_value:.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
