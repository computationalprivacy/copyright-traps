{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "# Enable hot autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, LlamaForCausalLM\n",
    "from utils import compute_perplexity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_TOKENIZER_PATH = \"<LLAMA_TOKENIZER_PATH>\"\n",
    "LLAMA_MODEL_PATH = \"<LLAMA_MODEL_PATH>\"\n",
    "\n",
    "# pickled pd.DataFrame, produced by inject_traps.py\n",
    "CANARY_INFO_PATH = \"<CANARY_INFO_PATH>\"\n",
    "\n",
    "# We've generated additional non-member canaries with the scripts `gen_traps.py`\n",
    "NON_MEMBERS_50_SMALL_PATH_TEMPLATE = \"<PATH_TO_NON_MEMBER_TRAPS_SEQ_LEN_%d>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_tokenizer = LlamaTokenizer.from_pretrained(LLAMA_TOKENIZER_PATH, torch_dtype=torch.float16)\n",
    "llama_model = LlamaForCausalLM.from_pretrained(LLAMA_MODEL_PATH)\n",
    "\n",
    "croissant_tokenizer = AutoTokenizer.from_pretrained(\"croissantllm/base_190k\")\n",
    "croissant_model = AutoModelForCausalLM.from_pretrained(\"croissantllm/base_190k\")\n",
    "\n",
    "croissant_tokenizer.pad_token = croissant_tokenizer.eos_token\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "\n",
    "croissant_model = croissant_model.to(\"cuda:0\")\n",
    "llama_model = llama_model.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CANARY_INFO_PATH, \"rb\") as f:\n",
    "    canary_info = pickle.load(f)\n",
    "canary_info[\"raw_canaries\"] = llama_tokenizer.batch_decode(canary_info.canary_tokens)\n",
    "\n",
    "non_members = {}\n",
    "for seq_len in [25, 50, 100]:\n",
    "    small_path = NON_MEMBERS_50_SMALL_PATH_TEMPLATE % seq_len\n",
    "    with open(small_path, \"rb\") as f:\n",
    "        non_members[seq_len] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_set = set(canary_info.seq_len)\n",
    "ppl_set = set(canary_info.ppl_bucket)\n",
    "n_rep_set = set(canary_info.n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame()\n",
    "\n",
    "for seq_len, ppl, n_rep in tqdm(list(itertools.product(seq_len_set, ppl_set, n_rep_set))):\n",
    "    df_filter = canary_info[\n",
    "        (canary_info.seq_len == seq_len)\n",
    "        & (canary_info.ppl_bucket == ppl)\n",
    "        & (canary_info.n_rep == n_rep)\n",
    "    ]\n",
    "\n",
    "    df_res_tmp = compute_perplexity_df(\n",
    "        llama_model=llama_model,\n",
    "        croissant_model=croissant_model,\n",
    "        llama_tokenizer=llama_tokenizer,\n",
    "        croissant_tokenizer=croissant_tokenizer,\n",
    "        raw_canaries=df_filter.raw_canaries,\n",
    "    )\n",
    "\n",
    "    df_res_tmp[\"seq_len\"] = seq_len\n",
    "    df_res_tmp[\"ppl\"] = ppl\n",
    "    df_res_tmp[\"n_rep\"] = n_rep\n",
    "\n",
    "    df_res = pd.concat([df_res, df_res_tmp])\n",
    "\n",
    "\n",
    "for seq_len, ppl in tqdm(list(itertools.product(seq_len_set, ppl_set))):\n",
    "    key = (ppl * 10 + 1, ppl * 10 + 11)\n",
    "    raw_canaries = llama_tokenizer.batch_decode(non_members[seq_len][key][:, 1:])\n",
    "\n",
    "    df_res_tmp = compute_perplexity_df(\n",
    "        llama_model=llama_model,\n",
    "        croissant_model=croissant_model,\n",
    "        llama_tokenizer=llama_tokenizer,\n",
    "        croissant_tokenizer=croissant_tokenizer,\n",
    "        raw_canaries=raw_canaries,\n",
    "    )\n",
    "    df_res_tmp[\"seq_len\"] = seq_len\n",
    "    df_res_tmp[\"ppl\"] = ppl\n",
    "    df_res_tmp[\"n_rep\"] = 0\n",
    "\n",
    "    df_res = pd.concat([df_res, df_res_tmp])\n",
    "    \n",
    "df_res[\"ratio\"] = df_res.croissant_ppl / df_res.llama_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(18, 12))\n",
    "\n",
    "aucs = []\n",
    "\n",
    "for i, seq_len in enumerate([25, 50, 100]):\n",
    "    for j, n_rep in enumerate([1, 10, 100, 1000]):\n",
    "        y_raw = []\n",
    "        y_true = []\n",
    "        y_ratio = []\n",
    "        y_minkprob = []\n",
    "\n",
    "        members_tmp = df_res[(df_res.seq_len == seq_len) & (df_res.n_rep == n_rep)]\n",
    "        non_members_tmp = df_res[(df_res.seq_len == seq_len) & (df_res.n_rep == 0)]\n",
    "\n",
    "        n = min(len(members_tmp), len(non_members_tmp))\n",
    "        members_tmp = members_tmp[:n]\n",
    "        non_members_tmp = non_members_tmp[:n]\n",
    "\n",
    "        y_raw.extend(np.log(members_tmp[\"croissant_ppl\"]))\n",
    "        y_raw.extend(np.log(non_members_tmp[\"croissant_ppl\"]))\n",
    "        y_ratio.extend(members_tmp[\"ratio\"])\n",
    "        y_ratio.extend(non_members_tmp[\"ratio\"])\n",
    "        y_minkprob.extend(-members_tmp[\"minkprob\"])\n",
    "        y_minkprob.extend(-non_members_tmp[\"minkprob\"])\n",
    "\n",
    "        y_true.extend([0] * len(members_tmp))\n",
    "        y_true.extend([1] * len(non_members_tmp))\n",
    "\n",
    "        fpr_baseline, tpr_baseline, _ = roc_curve(y_true, y_raw)\n",
    "        fpr_ratio, tpr_ratio, _ = roc_curve(y_true, y_ratio)\n",
    "        fpr_minkprob, tpr_minkprob, _ = roc_curve(y_true, y_minkprob)\n",
    "\n",
    "        auc_ratio = auc(fpr_ratio, tpr_ratio)\n",
    "        auc_baseline = auc(fpr_baseline, tpr_baseline)\n",
    "        auc_minkprob = auc(fpr_minkprob, tpr_minkprob)\n",
    "\n",
    "        aucs.append((seq_len, n_rep, auc_ratio))\n",
    "\n",
    "        ax = axs[i, j]\n",
    "\n",
    "        ax.plot(fpr_baseline, tpr_baseline, label=f\"LOSS (AUC={auc_baseline:.3f})\")\n",
    "        ax.plot(fpr_ratio, tpr_ratio, label=f\"Ratio (AUC={auc_ratio:.3f})\")\n",
    "        ax.plot(fpr_minkprob, tpr_minkprob, label=f\"Min k-prob (AUC={auc_minkprob:.3f})\")\n",
    "        ax.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "        ax.set_xlabel(\"False Positive Rate\")\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"True Positive Rate\")\n",
    "        ax.set_title(f\"seq_len={seq_len}, n_rep = {n_rep}\")\n",
    "        ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
